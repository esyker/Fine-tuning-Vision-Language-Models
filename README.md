# Folder Structure
* lxmert contains code for the LXMERT model. [https://huggingface.co/docs/transformers/model_doc/lxmert](https://huggingface.co/docs/transformers/model_doc/lxmert).
* clip-vit contains code for fine-tuning the CLIP-ViT model. [https://huggingface.co/openai/clip-vit-base-patch32](https://huggingface.co/openai/clip-vit-base-patch32).
* vsr_eda contains code for the exploratory data analysis and data augmentation of the Visual Spatial Reasoning Dataset (VSR).
  
# Approach
  
![image](https://github.com/esyker/Fine-tuning-Vision-Language-Models/assets/50277636/136fe38f-1a60-405a-b516-a526b5a0734a)

![image](https://github.com/esyker/Fine-tuning-Vision-Language-Models/assets/50277636/59813815-c87c-4582-b102-c2a814d744ec)

![image](https://github.com/esyker/Fine-tuning-Vision-Language-Models/assets/50277636/309ad288-7b4b-4bdd-bff6-628a7a642fec)

![image](https://github.com/esyker/Fine-tuning-Vision-Language-Models/assets/50277636/1aa6d3a6-e415-4bcf-8ef2-e776566f5e63)

![image](https://github.com/esyker/Fine-tuning-Vision-Language-Models/assets/50277636/5c3f9e53-4e14-4d90-9ecb-8784c7c95642)

![image](https://github.com/esyker/Fine-tuning-Vision-Language-Models/assets/50277636/f143af4a-a103-40b9-8619-604c521201e8)

![image](https://github.com/esyker/Fine-tuning-Vision-Language-Models/assets/50277636/0e340a88-fad2-48ab-9848-bd9696e19c3f)

![image](https://github.com/esyker/Fine-tuning-Vision-Language-Models/assets/50277636/d1ad75a4-1d00-4c9b-8574-7254ef18acd3)

![image](https://github.com/esyker/Fine-tuning-Vision-Language-Models/assets/50277636/839ca14c-b802-4b64-857a-abc223870432)

# Results

<img width="376" alt="image" src="https://github.com/esyker/Fine-tuning-Vision-Language-Models/assets/50277636/38bc9b52-e7ad-4446-8e59-4f46c58f3886">

<img width="438" alt="image" src="https://github.com/esyker/Fine-tuning-Vision-Language-Models/assets/50277636/db1b626d-a634-4a8d-afc1-bb31b6582333">










