{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import LxmertTokenizer, LxmertConfig, LxmertModel, get_scheduler\n",
    "from modeling_frcnn import GeneralizedRCNN\n",
    "import utils\n",
    "from processing_image import Preprocess\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "import lmdb\n",
    "import pickle\n",
    "import time\n",
    "import io\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,dataset_path,image_path, only_vsr = False, vsr = None, vsr_image_path = './data/vsr-images', max_length = 77):\n",
    "        self.lxmert_tokenizer = LxmertTokenizer.from_pretrained(\"unc-nlp/lxmert-base-uncased\")\n",
    "        self.max_length = max_length\n",
    "        self.dataset_path = dataset_path\n",
    "        self.image_path = image_path\n",
    "        self.img_txns = [None, None]\n",
    "        if(only_vsr):#assess only for the vsr dataset\n",
    "            self.dataset = self.read_vsr_dataset(vsr)\n",
    "            vsr_img_env = lmdb.open(\n",
    "                vsr_image_path, readonly=True, create=False, readahead=not False\n",
    "            )\n",
    "            vsr_img_txn = vsr_img_env.begin(buffers=True)\n",
    "            self.img_txns[1]= vsr_img_txn\n",
    "        else:#assess for the SNLI-VE dataset\n",
    "            self.dataset = self.read_dataset(dataset_path)\n",
    "            img_env = lmdb.open(\n",
    "                self.image_path, readonly=True, create=False, readahead=not False\n",
    "            )\n",
    "            img_txn = img_env.begin(buffers=True)\n",
    "            self.img_txns[0]= img_txn\n",
    "            if(vsr):#add extra data to make model more reliable\n",
    "                vsr_img_env = lmdb.open(vsr_image_path, readonly=True, create=False, readahead=not False)\n",
    "                vsr_img_txn = vsr_img_env.begin(buffers=True)\n",
    "                self.img_txns[1]= vsr_img_txn\n",
    "                self.dataset = pd.concat([self.dataset, self.read_vsr_dataset('train.json'),\n",
    "                                self.read_vsr_dataset('test.json'), self.read_vsr_dataset('dev.json')], ignore_index=True)\n",
    "    \n",
    "    def read_vsr_dataset(self,dataset_name, dataset_path = '../visual-spatial-reasoning/',splits_path='splits/', \n",
    "                         image_path = 'images/',sort = False, encode_labels = False):\n",
    "        dataset = pd.read_json(dataset_path+splits_path+dataset_name, lines =True)\n",
    "        dataset = dataset[['caption','image','label']]\n",
    "        dataset.rename(columns = {'caption':'hypothesis', 'image':'Flickr30kID', 'label' : 'gold_label'}, inplace = True)\n",
    "        if encode_labels:\n",
    "            labels_encoding = {0:0,1:2}#leave the label 0 the same and convert 1 to 2 to mean entailment\n",
    "            dataset['gold_label']=dataset['gold_label'].apply(lambda label: labels_encoding[label])\n",
    "        if(dataset_name=='train.json'):\n",
    "            dataset.drop(labels=[1786,3569,4553,4912], axis=0, inplace = True)\n",
    "        elif(dataset_name=='test.json'):\n",
    "            dataset.drop(labels=[135,614,1071,1621,1850], axis=0, inplace = True)\n",
    "        elif(dataset_name=='dev.json'):\n",
    "            dataset.drop(labels=[807], axis=0, inplace = True)\n",
    "        dataset['img_txn'] = pd.Series(np.full((len(dataset.index)), 1, dtype=int), index=dataset.index)\n",
    "        dataset.reset_index(drop=True, inplace=True)\n",
    "        if sort:\n",
    "            dataset.sort_values(by=\"hypothesis\", key=lambda x: x.str.len(), inplace = True)\n",
    "        return dataset\n",
    "    \n",
    "    def read_dataset(self, url,sort = False):\n",
    "        dataset = pd.read_csv(url)\n",
    "        labels_encoding = {'contradiction':0,'neutral': 1,\n",
    "                           'entailment':2}\n",
    "        dataset = dataset[['hypothesis','Flickr30kID','gold_label']]\n",
    "        dataset['gold_label']=dataset['gold_label'].apply(lambda label: labels_encoding[label])\n",
    "        dataset['img_txn'] = pd.Series(np.full((len(dataset.index)), 0, dtype=int), index=dataset.index)\n",
    "        if sort:\n",
    "            dataset.sort_values(by=\"hypothesis\", key=lambda x: x.str.len(), inplace = True)\n",
    "        return dataset\n",
    "    \n",
    "    def get_text_features(self,text): \n",
    "        #preprocess text\n",
    "        inputs = self.lxmert_tokenizer(\n",
    "            text,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True,\n",
    "            return_attention_mask=True,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return inputs\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.dataset.loc[idx]\n",
    "        img_name = sample['Flickr30kID']\n",
    "        text = sample['hypothesis']\n",
    "        label = sample['gold_label']\n",
    "        inputs = self.get_text_features(text)\n",
    "        item_img = pickle.loads(self.img_txns[sample['img_txn']].get(img_name.encode()))\n",
    "        \n",
    "        item = {'input_ids': inputs['input_ids'][0].to(torch.int32),\n",
    "                'attention_mask': inputs['attention_mask'][0].to(torch.bool),\n",
    "                'token_type_ids': inputs['token_type_ids'][0].to(torch.int32),\n",
    "                'normalized_boxes': torch.tensor(item_img['normalized_boxes'][0], dtype = torch.float32),\n",
    "                'features': torch.tensor(item_img['features'][0], dtype = torch.float32),\n",
    "                'label': torch.tensor(label,dtype = torch.long)}\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset.index)\n",
    "    \n",
    "    def __exit__(self):\n",
    "        self.img_env.close()\n",
    "        self.env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTrainer():\n",
    "    def __init__(self,model,train,eval_test, device = None, num_labels = 3):\n",
    "        self.device = device\n",
    "        self.model = model\n",
    "        self.train = train\n",
    "        self.eval_test = eval_test\n",
    "        self.test_acc_list = []#init\n",
    "        self.model_path = \"./models/new_my_model_epoch_\"\n",
    "        self.num_labels = num_labels\n",
    "        self.config_problem_type = \"single_label_classification\"\n",
    "        if self.config_problem_type == \"single_label_classification\":\n",
    "          self.loss_fct = torch.nn.CrossEntropyLoss()\n",
    "          self.output_loss = lambda output,labels : self.loss_fct(output.logits.view(-1, self.num_labels), labels.view(-1)) \n",
    "        elif self.config_problem_type == \"regression\":\n",
    "          self.loss_fct = torch.nn.MSELoss()\n",
    "          if self.num_labels == 1: self.output_loss = lambda output,labels : self.loss_fct(output.logits.squeeze(), labels.squeeze())\n",
    "          else: self.output_loss =  lambda output,labels : self.loss_fct(output.logits, labels)\n",
    "        elif self.config_problem_type == \"multi_label_classification\":\n",
    "          self.loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "          self.output_loss = lambda output,labels : self.loss_fct(output.logits, labels)\n",
    "\n",
    "    def train_model(self,batch_size = None, lr= None, epochs=None):\n",
    "        optimizer = AdamW(self.model.parameters(), lr=lr)\n",
    "        train_loader = DataLoader(self.train, batch_size=batch_size, shuffle=True, num_workers = 4)\n",
    "        lr_scheduler = get_scheduler(\n",
    "            name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps= epochs * len(train_loader)\n",
    "        )\n",
    "        for epoch in range(epochs):\n",
    "            progress_bar = tqdm(range(math.ceil(len(self.train)/batch_size)))\n",
    "            train_losses = []\n",
    "            for item in train_loader:\n",
    "                \"\"\"\n",
    "                print(item.keys())\n",
    "                for key, value in item.items() :\n",
    "                    print(value.shape)\n",
    "                    print(key,'\\n',value)\n",
    "                \"\"\"\n",
    "                item['input_ids']=item['input_ids'].to(self.device)\n",
    "                item['attention_mask']= item['attention_mask'].to(self.device)\n",
    "                item['token_type_ids']= item['token_type_ids'].to(self.device)\n",
    "                item['normalized_boxes'] = item['normalized_boxes'].to(self.device)\n",
    "                item['features']= item['features'].to(self.device)\n",
    "                item['label'] = item['label'].to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model.forward(item)\n",
    "                label = item['label']\n",
    "                loss = self.output_loss(outputs, label)\n",
    "                train_losses.append(loss)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                lr_scheduler.step()\n",
    "                progress_bar.update(1)\n",
    "            print(\"Saving model ....\")\n",
    "            model.save_model(self.model_path+str(epoch))\n",
    "            print(\"Model Saved!\")\n",
    "            test_acc = self.eval_test.evaluate(batch_size = batch_size)\n",
    "            self.test_acc_list.append(test_acc)\n",
    "            print('--- Epoch ',epoch,' Acc: ',test_acc)\n",
    "            mean_loss = torch.tensor(train_losses).mean().item()\n",
    "            print('Training loss: %.4f' % (mean_loss))\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyEvaluator():\n",
    "  def __init__(self,model,test, device = None):\n",
    "    self.test_dataset = test\n",
    "    self.model = model\n",
    "    self.device = device\n",
    "  \n",
    "  def evaluate(self, batch_size = 8):\n",
    "      self.model.eval()\n",
    "      loader = DataLoader(self.test_dataset, batch_size=batch_size, shuffle = False, num_workers = 4)\n",
    "      n_correct = 0\n",
    "      n_possible = 0\n",
    "      for item in loader:\n",
    "        item['input_ids']=item['input_ids'].to(self.device)\n",
    "        item['attention_mask']= item['attention_mask'].to(self.device)\n",
    "        item['token_type_ids']= item['token_type_ids'].to(self.device)\n",
    "        item['normalized_boxes'] = item['normalized_boxes'].to(self.device)\n",
    "        item['features']= item['features'].to(self.device)\n",
    "        item['label'] = item['label'].to(self.device)\n",
    "        y_hat = self.model.predict(item)\n",
    "        y = item['label']\n",
    "        n_correct += (y == y_hat).sum().item()\n",
    "        n_possible += float(y.shape[0])\n",
    "      self.model.train()\n",
    "      return n_correct / n_possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lxmert(LxmertModel):\n",
    "    def __init__(self,num_labels=3):\n",
    "        super().__init__(LxmertConfig.from_pretrained(\"unc-nlp/lxmert-base-uncased\"))\n",
    "        self.num_labels = num_labels\n",
    "        self.classification = torch.nn.Linear(self.config.hidden_size, self.num_labels)\n",
    "        # don't forget to init the weights for the new layers\n",
    "        #self.init_weights()\n",
    "    \n",
    "    def forward(self,item):       \n",
    "        input_ids = item['input_ids']\n",
    "        attention_mask=item['attention_mask']\n",
    "        token_type_ids=item['token_type_ids']\n",
    "        features = item['features']\n",
    "        normalized_boxes = item['normalized_boxes']\n",
    "        \n",
    "        output = super().forward(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            visual_feats=features,\n",
    "            visual_pos=normalized_boxes,\n",
    "            token_type_ids=token_type_ids,\n",
    "            return_dict=True,\n",
    "            output_attentions=False,\n",
    "        )\n",
    "        \n",
    "        output.logits = self.classification(output.pooled_output)\n",
    "        return output\n",
    "    \n",
    "    def predict(self,item):\n",
    "      \"\"\"\n",
    "      item (n_examples x n_features)\n",
    "      \"\"\"\n",
    "      scores = model(item)  # (n_examples x n_classes)\n",
    "      predicted_labels = scores.logits.argmax(dim=-1)  # (n_examples)\n",
    "      return predicted_labels\n",
    "\n",
    "    def save_model(self,path):\n",
    "        torch.save(self.state_dict(), path)\n",
    "        \n",
    "    def load_model(self,path):\n",
    "        self.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = \"cpu\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.get_device_name(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Lxmert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = MyDataset(\"../e-ViL/data/esnlive_train.csv\",\n",
    "                      \"./data/my_image_db\",\n",
    "                      max_length = 77, only_vsr = True, vsr= 'train.json')\n",
    "test = MyDataset(\"../e-ViL/data/esnlive_test.csv\",\n",
    "                      \"./data/my_image_db\",\n",
    "                      max_length = 77,\n",
    "                        only_vsr = True, vsr='test.json')\n",
    "dev = MyDataset(\"../e-ViL/data/esnlive_dev.csv\",\n",
    "                      \"./data/my_image_db\",\n",
    "                      max_length = 77,  only_vsr = True, vsr= 'dev.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train))\n",
    "print(len(test))\n",
    "print(len(dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "task = 'train'\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "lr = 1e-5/math.sqrt(2)\n",
    "if task =='train':\n",
    "    test_evaluator = MyEvaluator(model,test, device = device)\n",
    "    dev_evaluator = MyEvaluator(model,dev, device = device)\n",
    "    trainer = MyTrainer(model,train,test_evaluator, device = device)\n",
    "    model = model.to(device)\n",
    "    print(\"-----Training Model-----\")\n",
    "    trainer.train_model(epochs=epochs ,batch_size = batch_size, lr = lr)\n",
    "    print('----Training finished-----')\n",
    "    dev_acc = dev_evaluator.evaluate(batch_size = batch_size)\n",
    "    print(\"---- Dev Acc: \",dev_acc)\n",
    "elif task =='test':\n",
    "    model = model.to(device)\n",
    "    model.load_model(\"my_model_epoch_9\")\n",
    "    evaluator = MyEvaluator(model,dev, device = device)\n",
    "    acc = evaluator.evaluate(batch_size = batch_size)\n",
    "    print(acc)\n",
    "    #output = run_example(model,train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import psutil\n",
    "# gives a single float value\n",
    "print(psutil.cpu_percent())\n",
    "# gives an object with many fields\n",
    "print(psutil.virtual_memory())\n",
    "# you can convert that object to a dictionary \n",
    "print(dict(psutil.virtual_memory()._asdict()))\n",
    "# you can have the percentage of used RAM\n",
    "print(psutil.virtual_memory().percent)\n",
    "# you can calculate percentage of available memory\n",
    "print(psutil.virtual_memory().available * 100 / psutil.virtual_memory().total)\n",
    "print(psutil.virtual_memory().total/1024/1024/1024)\n",
    "print(psutil.virtual_memory().available/1024/1024/1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_gpus = [torch.cuda.device(i) for i in range(torch.cuda.device_count())]\n",
    "available_gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(torch.cuda.device_count()):\n",
    "    #Check CUDA memory usage\n",
    "    t = torch.cuda.get_device_properties(i).total_memory\n",
    "    r = torch.cuda.memory_reserved(i)\n",
    "    a = torch.cuda.memory_allocated(i)\n",
    "    f = r-a  # free inside reserved\n",
    "    name = torch.cuda.get_device_name(i)\n",
    "    print('------- Device ',i,' name:',name,' ------')\n",
    "    print('t ',t/1024/1024/1024)\n",
    "    print('r ',r/1024/1024/1024)\n",
    "    print('a ',a/1024/1024/1024)\n",
    "    print('f ',f/1024/1024/1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset\n",
    "import gc\n",
    "import torch\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "del(variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
